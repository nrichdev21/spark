{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://MSI:4041\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1605140996360)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@77752ce8\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n",
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "|summary|      Date|              Open|              High|               Low|             Close|              Volume|         Adj Close|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "|  count|      1259|              1259|              1259|              1259|              1259|                1259|              1259|\n",
      "|   mean|      null|230.39351086656092|233.97320872915006|226.80127876251044|  230.522453845909|2.5634836060365368E7|55.610540036536875|\n",
      "| stddev|      null|164.37456353264244| 165.9705082667129| 162.6506358235739|164.40918905512854| 2.306312683388607E7|35.186669331525486|\n",
      "|    min|2011-10-24|         53.990001|         55.480001|             52.81|              53.8|             3531300|          7.685714|\n",
      "|    max|2016-10-24|        708.900017|        716.159996|        697.569984|        707.610001|           315541800|        130.929993|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "\n",
      "+----------+----------+------------------+----------+-----------------+---------+------------------+\n",
      "|      Date|      Open|              High|       Low|            Close|   Volume|         Adj Close|\n",
      "+----------+----------+------------------+----------+-----------------+---------+------------------+\n",
      "|2011-10-24|119.100002|120.28000300000001|115.100004|       118.839996|120460200|         16.977142|\n",
      "|2011-10-25| 74.899999|         79.390001| 74.249997|        77.370002|315541800|11.052857000000001|\n",
      "|2011-10-26|     78.73|         81.420001| 75.399997|        79.400002|148733900|         11.342857|\n",
      "|2011-10-27| 82.179998| 82.71999699999999| 79.249998|80.86000200000001| 71190000|11.551428999999999|\n",
      "|2011-10-28| 80.280002|         84.660002| 79.599999|84.14000300000001| 57769600|             12.02|\n",
      "+----------+----------+------------------+----------+-----------------+---------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[2011-10-24,119.100002,120.28000300000001,115.100004,118.839996,120460200,16.977142]\n",
      "[2011-10-25,74.899999,79.390001,74.249997,77.370002,315541800,11.052857000000001]\n",
      "[2011-10-26,78.73,81.420001,75.399997,79.400002,148733900,11.342857]\n",
      "[2011-10-27,82.179998,82.71999699999999,79.249998,80.86000200000001,71190000,11.551428999999999]\n",
      "[2011-10-28,80.280002,84.660002,79.599999,84.14000300000001,57769600,12.02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"../../data/ml_scala/Netflix_2011_2016.csv\")\n",
    "\n",
    "df.columns\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "df.show(5)\n",
    "\n",
    "for(row <- df.head(5)){\n",
    "    println(row)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+-----------------+---------+------------------+--------------------+\n",
      "|      Date|      Open|              High|       Low|            Close|   Volume|         Adj Close|            HV_Ratio|\n",
      "+----------+----------+------------------+----------+-----------------+---------+------------------+--------------------+\n",
      "|2011-10-24|119.100002|120.28000300000001|115.100004|       118.839996|120460200|         16.977142|9.985040951285156E-7|\n",
      "|2011-10-25| 74.899999|         79.390001| 74.249997|        77.370002|315541800|11.052857000000001|2.515989989281927E-7|\n",
      "|2011-10-26|     78.73|         81.420001| 75.399997|        79.400002|148733900|         11.342857|5.474206014903126E-7|\n",
      "|2011-10-27| 82.179998| 82.71999699999999| 79.249998|80.86000200000001| 71190000|11.551428999999999|1.161960907430818...|\n",
      "|2011-10-28| 80.280002|         84.660002| 79.599999|84.14000300000001| 57769600|             12.02|1.465476686700271...|\n",
      "+----------+----------+------------------+----------+-----------------+---------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Add new column with HV Ratio\n",
    "val df2 = df.withColumn(\"HV_Ratio\", df(\"High\") / df(\"Volume\"))\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+----------+----------+----------+--------+------------------+--------------------+\n",
      "|      Date|             Open|      High|       Low|     Close|  Volume|         Adj Close|            HV_Ratio|\n",
      "+----------+-----------------+----------+----------+----------+--------+------------------+--------------------+\n",
      "|2015-07-13|686.6900019999999|716.159996|686.550026|707.610001|33205200|101.08714300000001|2.156770614241143E-5|\n",
      "+----------+-----------------+----------+----------+----------+--------+------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Find the peak High\n",
    "df2.orderBy($\"High\".desc).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         avg(Volume)|\n",
      "+--------------------+\n",
      "|2.5634836060365368E7|\n",
      "+--------------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Average Closing Price\n",
    "df2.select(mean(\"Volume\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(Volume)|\n",
      "+-----------+\n",
      "|    3531300|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|max(Volume)|\n",
      "+-----------+\n",
      "|  315541800|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Max and Min Volume\n",
    "df2.select(min(\"Volume\")).show()\n",
    "df2.select(max(\"Volume\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Long = 1218\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Number of days where close was lower than $600\n",
    "df2.filter($\"Close\" < 600).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res6: Double = 4.924543288324067\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Percentage of time high was greater than $500\n",
    "(df2.filter($\"High\">500).count()*1.0/df.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   corr(High, Low)|\n",
      "+------------------+\n",
      "|0.9996836884310145|\n",
      "+------------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Correlation between High and Low\n",
    "df2.select(corr(\"High\",\"Low\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+----------+----------+---------+---------+--------------------+----+-----+\n",
      "|      Date|      Open|              High|       Low|     Close|   Volume|Adj Close|            HV_Ratio|Year|Month|\n",
      "+----------+----------+------------------+----------+----------+---------+---------+--------------------+----+-----+\n",
      "|2011-10-24|119.100002|120.28000300000001|115.100004|118.839996|120460200|16.977142|9.985040951285156E-7|2011|   10|\n",
      "+----------+----------+------------------+----------+----------+---------+---------+--------------------+----+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "+----+------------------+\n",
      "|Year|         Year_High|\n",
      "+----+------------------+\n",
      "|2011|120.28000300000001|\n",
      "|2012|        133.429996|\n",
      "|2013|        389.159988|\n",
      "|2014|        489.290024|\n",
      "|2015|        716.159996|\n",
      "|2016|129.28999299999998|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df3: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 8 more fields]\r\n",
       "df4: org.apache.spark.sql.DataFrame = [Year: int, Year_High: double]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Max High per year\n",
    "val df3 = df2.withColumn(\"Year\", year(df2(\"Date\"))).withColumn(\"Month\", month(df2(\"Date\")))\n",
    "df3.show(1)\n",
    "\n",
    "val df4 = df3.groupBy(\"Year\").max(\"High\").orderBy($\"Year\").withColumnRenamed(\"max(High)\", \"Year_High\")\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Month|         Avg_Close|\n",
      "+-----+------------------+\n",
      "|    1|212.22613874257422|\n",
      "|    2| 254.1954634020619|\n",
      "|    3| 249.5825228971963|\n",
      "|    4|246.97514271428562|\n",
      "|    5|264.37037614150944|\n",
      "|    6| 295.1597153490566|\n",
      "|    7|243.64747528037387|\n",
      "|    8|195.25599892727263|\n",
      "|    9|206.09598121568627|\n",
      "|   10|205.93297300900903|\n",
      "|   11| 194.3172275445545|\n",
      "|   12| 199.3700942358491|\n",
      "+-----+------------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// Average Close for each calendar month\n",
    "df3.groupBy(\"Month\").mean(\"Close\").orderBy(\"Month\").withColumnRenamed(\"avg(Close)\",\"Avg_Close\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
